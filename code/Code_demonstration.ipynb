{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & Generation for Paper \"Responding to the Call: Exploring Automatic Music Composition Using a Knowledge-Enhanced Model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set GPU\n",
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"2,3\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import time\n",
    "import glob\n",
    "import datetime\n",
    "import random\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from main_knowledge import *\n",
    "import saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###--- data ---###\n",
    "path_data_root = './dataset/'\n",
    "path_test_data = os.path.join(path_data_root, 'test.npz')\n",
    "path_train_data = os.path.join(path_data_root, 'train.npz')\n",
    "path_dictionary =  os.path.join(path_data_root, 'dictionary.pkl')\n",
    "\n",
    "##uncomment the following to run on the complete training and test data\n",
    "###--- data ---###\n",
    "# path_data_root = '../train_test_data/'\n",
    "# path_test_data = os.path.join(path_data_root, 'test.npz')\n",
    "# path_train_data = os.path.join(path_data_root, 'train.npz')\n",
    "# path_dictionary =  os.path.join(path_data_root, 'dictionary.pkl')\n",
    "\n",
    "\n",
    "\n",
    "###--- training config ---###\n",
    "path_exp = './exp'\n",
    "batch_size =8\n",
    "init_lr = 0.0001\n",
    "max_grad_norm = 3\n",
    "path_gendir = 'gen_midis'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") ## specify the GPU id's, GPU id's start from 0.\n",
    "# device=torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data():\n",
    "  dictionary = pickle.load(open(path_dictionary, 'rb'))\n",
    "  event2word, word2event = dictionary\n",
    "  train_data = np.load(path_train_data,allow_pickle=True)\n",
    "  return train_data, event2word, word2event, dictionary\n",
    "def get_test_data():\n",
    "  dictionary = pickle.load(open(path_dictionary, 'rb'))\n",
    "  event2word, word2event = dictionary\n",
    "  test_data = np.load(path_test_data,allow_pickle=True)\n",
    "  return test_data, event2word, word2event, dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of classes: [234, 135, 18, 7, 130, 22, 130]\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train_data, event2word, word2event, dictionary = get_train_data()\n",
    "test_data, event2word, word2event, dictionary = get_test_data()\n",
    "\n",
    "\n",
    "\n",
    "# config\n",
    "n_class = []\n",
    "for key in event2word.keys():\n",
    "    n_class.append(len(dictionary[0][key]))\n",
    "print('num of classes:', n_class)\n",
    "\n",
    "# # unpack\n",
    "train_x = train_data['x']\n",
    "train_y = train_data['y']\n",
    "train_mask = train_data['mask']\n",
    "\n",
    "\n",
    "fact_candidate=np.load('./dataset/knowledge.npy',allow_pickle=True)\n",
    "\n",
    "# uncomment the following to load predefined external knowledge\n",
    "# fact_candidate=torch.load('../train_test_data/external_knowledge/candidate_train')\n",
    "\n",
    "\n",
    "test_x = test_data['x'][:]\n",
    "test_y = test_data['y'][:]\n",
    "test_mask = test_data['mask'][:]\n",
    "\n",
    "# run\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>: [234, 135, 18, 7, 130, 22, 130]\n",
      "n_parameters: 46,878,212\n"
     ]
    }
   ],
   "source": [
    "net = TransformerModel(n_class)\n",
    "info_load_model=False\n",
    "net= nn.DataParallel(net)\n",
    "net.to(device)\n",
    "net.train()\n",
    "n_parameters = network_paras(net)\n",
    "print('n_parameters: {:,}'.format(n_parameters))\n",
    "# # optimizers\n",
    "optimizer = optim.Adam(net.parameters(), lr=init_lr)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fec99197da645c8992ec05632b2dcd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------.158813, 1.423457, 0.770577, 3.482129, 1.942377, 3.216327\n",
      "epoch: 1/5 | Loss: 4.841426562714992 | time: 0:00:05.186317\n",
      " [*] saving model to ./exp, name: loss_high_epoch_0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57f58d417cdf4715ac8d65f83913c7f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------.627180, 1.287603, 0.748454, 3.203340, 1.603609, 2.664313\n",
      "epoch: 2/5 | Loss: 2.9770830225445284 | time: 0:00:09.827507\n",
      " [*] saving model to ./exp, name: loss_high_epoch_1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86a307bdfce0441b9fcc3e1e7de5a4f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------.536394, 1.173188, 0.614496, 3.062819, 1.500539, 2.432902\n",
      "epoch: 3/5 | Loss: 2.5122201440953065 | time: 0:00:14.423437\n",
      " [*] saving model to ./exp, name: loss_high_epoch_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ba7c359c7bc418190eeaf6469fcb67b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------.501772, 1.050323, 0.537573, 2.971943, 1.493165, 2.343086\n",
      "epoch: 4/5 | Loss: 2.3280702231306383 | time: 0:00:19.053903\n",
      " [*] saving model to ./exp, name: loss_high_epoch_3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68766e68c1c04af1a086764b7d26365d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------.477591, 1.011883, 0.513849, 2.932106, 1.471540, 2.282391\n",
      "epoch: 5/5 | Loss: 2.210638406372834 | time: 0:00:23.678842\n",
      " [*] saving model to ./exp, name: loss_high_epoch_4\n"
     ]
    }
   ],
   "source": [
    "saver_agent = saver.Saver(path_exp)\n",
    "###TAsk1 ###\n",
    "num_batch = len(train_x) // batch_size\n",
    "candidate_number=3\n",
    "n_epoch = 5\n",
    "start_time = time.time()\n",
    "for epoch in range(n_epoch):            \n",
    "    acc_loss = 0\n",
    "    acc_losses = np.zeros(7)\n",
    "    with tqdm(range(num_batch)) as bar:\n",
    "        for bidx in range(num_batch): # num_batch \n",
    "          # index\n",
    "            bidx_st = batch_size * bidx\n",
    "            bidx_ed = batch_size * (bidx + 1)\n",
    "          # unpack batch data\n",
    "            batch_x = train_x[bidx_st:bidx_ed]\n",
    "            batch_y = train_y[bidx_st:bidx_ed]\n",
    "            batch_mask = train_mask[bidx_st:bidx_ed]\n",
    "            batch_x = torch.from_numpy(batch_x).long().to(device)\n",
    "            batch_y = torch.from_numpy(batch_y).long().to(device)\n",
    "            batch_mask = torch.from_numpy(batch_mask).float().to(device)\n",
    "            if isinstance(net, torch.nn.DataParallel):\n",
    "                net = net.module\n",
    "          # run\n",
    "            # first task  \n",
    "            t1=torch.cat([batch_y[:,:-1],torch.LongTensor([[0,0,0,0,0,0,0]]).expand(batch_y.shape[0],1,7).to('cuda')],1)\n",
    "            t2=torch.cat([batch_y[:,1:],torch.LongTensor([[0,0,0,0,0,0,0]]).expand(batch_y.shape[0],1,7).to('cuda')],1)\n",
    "            batch_mask1=torch.cat([batch_mask[:,:-1],torch.LongTensor([[0]]).expand(batch_y.shape[0],1).to('cuda')],1)\n",
    "\n",
    "            src_mask=[]\n",
    "            for i in range(len(batch_x)):\n",
    "                src_mask.append(int(torch.where(batch_x[i][:,3]==0)[0][0]))\n",
    "\n",
    "            tgt_mask=[]\n",
    "            for i in range(len(t1)):\n",
    "                tgt_mask.append(int(torch.where(t1[i][:,3]==0)[0][0]))\n",
    "\n",
    "            losses = net.train_step(batch_x, t1,t2,src_mask,tgt_mask,batch_mask1,None)\n",
    "            loss_task1 = (1*losses[0] + 1*losses[1] + 1*losses[2] + 1*losses[3] + 1*losses[4] + 1*losses[5] + 1*losses[6] ) / 7\n",
    "            \n",
    "                            \n",
    "            # second task                  \n",
    "            knowledge_base={}\n",
    "            knowledge_base['item']={}\n",
    "            knw_mask_t=[]\n",
    "            batch_knowledge={}\n",
    "            for idx in range(candidate_number):\n",
    "                batch_knowledge[idx] = fact_candidate[idx][bidx_st:bidx_ed]\n",
    "                batch_knowledge[idx] = torch.from_numpy(batch_knowledge[idx]).long().to(device)\n",
    "\n",
    "                knw_mask=[]\n",
    "                for j in range(len(batch_knowledge[idx])):\n",
    "                    knw_mask.append(int(torch.where(batch_knowledge[idx][j][:,3]==0)[0][0]))\n",
    "                knw_mask_t.append(knw_mask)\n",
    "\n",
    "            for i in range(candidate_number):    \n",
    "                knowledge_base['item'][i] =net.forward_hidden(batch_knowledge[i],knw_mask_t[i])\n",
    "\n",
    "            losses = net.train_step(batch_x, t1,t2,src_mask,tgt_mask,batch_mask1,knowledge_base['item'])\n",
    "            loss_task2 = (losses[0] + losses[1] + losses[2] + losses[3] + losses[4] + losses[5] + losses[6] ) / 7\n",
    "            \n",
    "            \n",
    "            \n",
    "            # third task                  \n",
    "            loss_task3=0\n",
    "            for can in range(candidate_number):\n",
    "                t1=torch.cat([batch_knowledge[can][:,:-1],torch.LongTensor([[0,0,0,0,0,0,0]]).expand(batch_knowledge[can].shape[0],1,7).to('cuda')],1)\n",
    "                t2=torch.cat([batch_knowledge[can][:,1:],torch.LongTensor([[0,0,0,0,0,0,0]]).expand(batch_knowledge[can].shape[0],1,7).to('cuda')],1)\n",
    "                mask_list=[]\n",
    "                for i in knw_mask_t[can]:\n",
    "                    mask=np.concatenate([np.ones(i),np.zeros(256-i)])\n",
    "                    mask_list.append(mask)\n",
    "                batch_mask=torch.tensor(mask_list).to(device)\n",
    "                batch_mask1=torch.cat([batch_mask[:,:-1],torch.LongTensor([[0]]).expand(batch_y.shape[0],1).to('cuda')],1)\n",
    "                tgt_mask=[]\n",
    "                for i in range(len(t1)):\n",
    "                    tgt_mask.append(int(torch.where(t1[i][:,3]==0)[0][0]))\n",
    "                losses = net.train_step(batch_x, t1,t2,src_mask,tgt_mask,batch_mask1,knowledge_base['item'])\n",
    "                loss_3 = (losses[0] + losses[1] + losses[2] + losses[3] + losses[4] + losses[5] + losses[6] ) / 7\n",
    "                loss_task3 +=loss_3\n",
    "            \n",
    "            loss_task3=loss_task3/candidate_number\n",
    "            \n",
    "#             loss=loss_task1\n",
    "            loss= loss_task1+(loss_task2+loss_task3)/2\n",
    "              # Update\n",
    "            net.zero_grad()\n",
    "            loss.backward()\n",
    "            if max_grad_norm is not None:\n",
    "                clip_grad_norm_(net.parameters(), max_grad_norm)\n",
    "            optimizer.step()\n",
    "              # print\n",
    "#             sys.stdout.write('{}/{} | Loss: {:06f} | {:04f}, {:04f}, {:04f}\\r'.format(\n",
    "#                   bidx, num_batch, loss, loss_task1, loss_task2, loss_task3))\n",
    "            sys.stdout.write('{}/{} | Loss: {:06f} | {:04f}, {:04f}, {:04f}, {:04f}, {:04f}, {:04f}, {:04f}\\r'.format(\n",
    "                          bidx, num_batch, loss, losses[0], losses[1], losses[2], losses[3], losses[4], losses[5], losses[6]))\n",
    "\n",
    "            sys.stdout.flush()\n",
    "            bar.update()\n",
    "              # acc\n",
    "\n",
    "            acc_losses += np.array([l.item() for l in losses])\n",
    "            acc_loss += loss.item()\n",
    "\n",
    "\n",
    "\n",
    "        # epoch loss\n",
    "    runtime = time.time() - start_time\n",
    "    epoch_loss = acc_loss / num_batch\n",
    "    acc_losses = acc_losses / num_batch\n",
    "    print('------------------------------------')\n",
    "    print('epoch: {}/{} | Loss: {} | time: {}'.format(\n",
    "            epoch+1, n_epoch, epoch_loss, str(datetime.timedelta(seconds=runtime))))\n",
    "\n",
    "    \n",
    "\n",
    "        # save model, with policy\n",
    "    loss = epoch_loss\n",
    "    if 0.4 < loss <= 1:\n",
    "        fn = int(loss * 10) * 10\n",
    "        saver_agent.save_model(net, name='loss_' + str(fn))\n",
    "    elif 0.01 < loss <= 0.40:\n",
    "        fn = int(loss * 100)\n",
    "        saver_agent.save_model(net, name='loss_' + str(fn))\n",
    "    elif loss <= 0.01:\n",
    "        print('Finished')\n",
    "    else:\n",
    "        saver_agent.save_model(net, name='loss_high'+ \"_epoch_\" + str(epoch))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>: [234, 135, 18, 7, 130, 22, 130]\n",
      " [o] using RNN backend.\n",
      "[*] load model from: ./exp/loss_80_params.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): TransformerModel(\n",
       "    (loss_func): CrossEntropyLoss()\n",
       "    (word_emb_tempo): Embeddings(\n",
       "      (lut): Embedding(234, 512)\n",
       "    )\n",
       "    (word_emb_chord): Embeddings(\n",
       "      (lut): Embedding(135, 256)\n",
       "    )\n",
       "    (word_emb_barbeat): Embeddings(\n",
       "      (lut): Embedding(18, 64)\n",
       "    )\n",
       "    (word_emb_type): Embeddings(\n",
       "      (lut): Embedding(7, 32)\n",
       "    )\n",
       "    (word_emb_pitch): Embeddings(\n",
       "      (lut): Embedding(130, 512)\n",
       "    )\n",
       "    (word_emb_duration): Embeddings(\n",
       "      (lut): Embedding(22, 128)\n",
       "    )\n",
       "    (word_emb_velocity): Embeddings(\n",
       "      (lut): Embedding(130, 512)\n",
       "    )\n",
       "    (pos_emb): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (in_linear): Linear(in_features=2016, out_features=512, bias=True)\n",
       "    (linear_knowledge): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (knowledge_selector): KnowledgeSelector(\n",
       "      (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "    )\n",
       "    (transformer_encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (attention): AttentionLayer(\n",
       "            (inner_attention): FullAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (attention): AttentionLayer(\n",
       "            (inner_attention): FullAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (attention): AttentionLayer(\n",
       "            (inner_attention): FullAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): TransformerEncoderLayer(\n",
       "          (attention): AttentionLayer(\n",
       "            (inner_attention): FullAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (4): TransformerEncoderLayer(\n",
       "          (attention): AttentionLayer(\n",
       "            (inner_attention): FullAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (5): TransformerEncoderLayer(\n",
       "          (attention): AttentionLayer(\n",
       "            (inner_attention): FullAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (transformer_decoder): RecurrentTransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): RecurrentTransformerDecoderLayer(\n",
       "          (self_attention): RecurrentAttentionLayer(\n",
       "            (inner_attention): RecurrentFullAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (cross_attention): RecurrentCrossAttentionLayer(\n",
       "            (inner_attention): RecurrentCrossFullAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): RecurrentTransformerDecoderLayer(\n",
       "          (self_attention): RecurrentAttentionLayer(\n",
       "            (inner_attention): RecurrentFullAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (cross_attention): RecurrentCrossAttentionLayer(\n",
       "            (inner_attention): RecurrentCrossFullAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): RecurrentTransformerDecoderLayer(\n",
       "          (self_attention): RecurrentAttentionLayer(\n",
       "            (inner_attention): RecurrentFullAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (cross_attention): RecurrentCrossAttentionLayer(\n",
       "            (inner_attention): RecurrentCrossFullAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): RecurrentTransformerDecoderLayer(\n",
       "          (self_attention): RecurrentAttentionLayer(\n",
       "            (inner_attention): RecurrentFullAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (cross_attention): RecurrentCrossAttentionLayer(\n",
       "            (inner_attention): RecurrentCrossFullAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (4): RecurrentTransformerDecoderLayer(\n",
       "          (self_attention): RecurrentAttentionLayer(\n",
       "            (inner_attention): RecurrentFullAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (cross_attention): RecurrentCrossAttentionLayer(\n",
       "            (inner_attention): RecurrentCrossFullAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (5): RecurrentTransformerDecoderLayer(\n",
       "          (self_attention): RecurrentAttentionLayer(\n",
       "            (inner_attention): RecurrentFullAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (cross_attention): RecurrentCrossAttentionLayer(\n",
       "            (inner_attention): RecurrentCrossFullAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (project_concat_type): Linear(in_features=544, out_features=512, bias=True)\n",
       "    (proj_tempo): Linear(in_features=512, out_features=234, bias=True)\n",
       "    (proj_chord): Linear(in_features=512, out_features=135, bias=True)\n",
       "    (proj_barbeat): Linear(in_features=512, out_features=18, bias=True)\n",
       "    (proj_type): Linear(in_features=512, out_features=7, bias=True)\n",
       "    (proj_pitch): Linear(in_features=512, out_features=130, bias=True)\n",
       "    (proj_duration): Linear(in_features=512, out_features=22, bias=True)\n",
       "    (proj_velocity): Linear(in_features=512, out_features=130, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = TransformerModel(n_class,is_training=False)\n",
    "info_load_model = (\"./exp/\",'80')\n",
    "# load model\n",
    "if info_load_model:\n",
    "    path_ckpt = info_load_model[0] # path to ckpt dir\n",
    "    loss = info_load_model[1] # loss\n",
    "    name = 'loss_' + str(loss)\n",
    "    path_saved_ckpt = os.path.join(path_ckpt, name + '_params.pt')\n",
    "    print('[*] load model from:',  path_saved_ckpt)\n",
    "#         net.load_state_dict(torch.load(path_saved_ckpt,map_location=device))\n",
    "    model_dict = net.state_dict()\n",
    "    pretrained_dict=torch.load(path_saved_ckpt)\n",
    "    net.load_state_dict(pretrained_dict)\n",
    "\n",
    "\n",
    "\n",
    "net= nn.DataParallel(net)\n",
    "net.to(device)\n",
    "# net.train()\n",
    "net.eval()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ generate ------\n",
      "bar: 1  ==Tempo_71        | E_m             | Beat_0          | Metrical        | 0               | 0               | Note_Velocity_30 | \n",
      "bar: 1  ==0               | 0               | 0               | Note            | Note_Pitch_88   | Note_Duration_240 | Note_Velocity_73 | \n",
      "bar: 1  ==Tempo_71        | CONTI           | Beat_5          | Metrical        | 0               | 0               | Note_Velocity_126 | \n",
      "bar: 1  ==0               | 0               | 0               | Note            | Note_Pitch_76   | Note_Duration_0 | Note_Velocity_39 | \n",
      "bar: 1  ==0               | 0               | 0               | Note            | Note_Pitch_61   | Note_Duration_360 | Note_Velocity_46 | \n",
      "bar: 1  ==CONTI           | CONTI           | Beat_4          | Metrical        | 0               | 0               | Note_Velocity_98 | \n",
      "bar: 1  ==0               | 0               | 0               | Note            | Note_Pitch_60   | Note_Duration_480 | Note_Velocity_74 | \n",
      "bar: 1  ==0               | 0               | Beat_5          | Note            | Note_Pitch_68   | Note_Duration_0 | Note_Velocity_99 | \n",
      "bar: 1  ==0               | 0               | 0               | Note            | Note_Pitch_60   | Note_Duration_1200 | Note_Velocity_64 | \n",
      "bar: 1  ==CONTI           | CONTI           | Beat_3          | Metrical        | 0               | Note_Duration_1080 | Note_Velocity_19 | \n",
      "bar: 1  ==0               | 0               | 0               | Note            | Note_Pitch_67   | Note_Duration_0 | Note_Velocity_88 | \n",
      "bar: 1  ==0               | 0               | 0               | Note            | Note_Pitch_47   | Note_Duration_720 | Note_Velocity_41 | \n",
      "bar: 1  ==CONTI           | CONTI           | Beat_10         | Metrical        | 0               | 0               | Note_Velocity_108 | \n",
      "bar: 1  ==0               | 0               | 0               | Note            | Note_Pitch_76   | Note_Duration_120 | Note_Velocity_92 | \n",
      "bar: 1  ==0               | 0               | 0               | Note            | Note_Pitch_66   | Note_Duration_120 | Note_Velocity_4 | \n",
      "bar: 1  ==0               | 0               | 0               | Note            | Note_Pitch_59   | Note_Duration_600 | Note_Velocity_92 | \n",
      "bar: 1  ==CONTI           | A_M7            | Beat_4          | Metrical        | 0               | 0               | Note_Velocity_11 | \n",
      "bar: 1  ==0               | 0               | 0               | Note            | Note_Pitch_66   | Note_Duration_240 | Note_Velocity_66 | \n",
      "bar: 1  ==0               | 0               | 0               | Note            | Note_Pitch_54   | Note_Duration_480 | Note_Velocity_68 | \n",
      "bar: 1  ==CONTI           | CONTI           | Beat_12         | Metrical        | 0               | 0               | Note_Velocity_84 | \n",
      "bar: 1  ==0               | 0               | 0               | Note            | Note_Pitch_76   | Note_Duration_720 | Note_Velocity_63 | \n",
      "bar: 1  ==0               | 0               | 0               | Note            | Note_Pitch_60   | Note_Duration_120 | Note_Velocity_20 | \n",
      "bar: 1  ==0               | 0               | 0               | Note            | Note_Pitch_45   | Note_Duration_0 | Note_Velocity_40 | \n",
      "bar: 1  ==CONTI           | CONTI           | Beat_0          | Metrical        | 0               | 0               | Note_Velocity_87 | \n",
      "bar: 1  ==0               | 0               | 0               | Note            | Note_Pitch_78   | Note_Duration_960 | Note_Velocity_100 | \n",
      "bar: 1  ==0               | 0               | 0               | Note            | Note_Pitch_62   | Note_Duration_480 | Note_Velocity_117 | \n",
      "bar: 1  ==0               | 0               | 0               | Note            | Note_Pitch_54   | Note_Duration_0 | Note_Velocity_121 | \n",
      "bar: 1  ==CONTI           | CONTI           | Beat_2          | Metrical        | 0               | Note_Duration_840 | Note_Velocity_99 | \n",
      "bar: 1  ==0               | 0               | 0               | Note            | Note_Pitch_73   | Note_Duration_240 | Note_Velocity_8 | \n",
      "bar: 1  ==0               | 0               | 0               | Note            | Note_Pitch_64   | Note_Duration_600 | Note_Velocity_100 | \n",
      "bar: 1  ==0               | B_M             | 0               | Note            | Note_Pitch_64   | Note_Duration_600 | Note_Velocity_2 | \n",
      "bar: 1  ==0               | 0               | 0               | Note            | 0               | Note_Duration_600 | Note_Velocity_96 | \n",
      "bar: 1  ==0               | B_+             | Bar             | EOS             | 0               | Note_Duration_840 | Note_Velocity_82 | \n",
      "\n",
      "--------[Done]--------\n",
      "(33, 7)\n",
      "------ generate ------\n",
      "bar: 1  ==Tempo_70        | E_m             | Beat_0          | Metrical        | 0               | 0               | Note_Velocity_82 | \n",
      "bar: 1  ==0               | 0               | 0               | Note            | Note_Pitch_50   | Note_Duration_720 | Note_Velocity_82 | \n",
      "bar: 1  ==0               | E_m             | Beat_4          | Metrical        | 0               | 0               | Note_Velocity_38 | \n",
      "bar: 1  ==Tempo_239       | D#_7            | 0               | EOS             | 0               | Note_Duration_720 | Note_Velocity_52 | \n",
      "\n",
      "--------[Done]--------\n",
      "(4, 7)\n",
      "------ generate ------\n",
      "bar: 1  ==Tempo_71        | C_M7            | Beat_6          | Metrical        | 0               | 0               | Note_Velocity_23 | \n",
      "bar: 1  ==0               | 0               | 0               | Note            | Note_Pitch_64   | Note_Duration_720 | Note_Velocity_52 | \n",
      "bar: 1  ==CONTI           | CONTI           | Beat_2          | Metrical        | 0               | Note_Duration_360 | Note_Velocity_51 | \n",
      "bar: 1  ==0               | 0               | 0               | Note            | Note_Pitch_76   | Note_Duration_240 | Note_Velocity_3 | \n",
      "bar: 1  ==0               | 0               | 0               | Note            | Note_Pitch_57   | Note_Duration_840 | Note_Velocity_69 | \n",
      "bar: 1  ==CONTI           | CONTI           | Beat_0          | Metrical        | 0               | 0               | Note_Velocity_9 | \n",
      "bar: 1  ==0               | 0               | 0               | Note            | Note_Pitch_78   | Note_Duration_360 | Note_Velocity_58 | \n",
      "bar: 1  ==CONTI           | CONTI           | Beat_2          | Metrical        | 0               | 0               | Note_Velocity_98 | \n",
      "bar: 1  ==0               | 0               | 0               | Note            | Note_Pitch_66   | Note_Duration_480 | Note_Velocity_65 | \n",
      "bar: 1  ==0               | 0               | Beat_10         | Note            | Note_Pitch_55   | Note_Duration_600 | Note_Velocity_42 | \n",
      "bar: 1  ==0               | C_M             | Beat_8          | Metrical        | 0               | 0               | Note_Velocity_76 | \n",
      "bar: 1  ==Tempo_213       | 0               | Beat_0          | EOS             | 0               | Note_Duration_720 | Note_Velocity_122 | \n",
      "\n",
      "--------[Done]--------\n",
      "(12, 7)\n",
      "------ generate ------\n",
      "bar: 1  ==Tempo_162       | B_M             | Beat_14         | SPC             | Note_Pitch_55   | Note_Duration_720 | Note_Velocity_114 | \n",
      "bar: 1  ==0               | 0               | 0               | Note            | Note_Pitch_52   | Note_Duration_1560 | Note_Velocity_14 | \n",
      "bar: 1  ==CONTI           | CONTI           | Beat_7          | Metrical        | 0               | 0               | Note_Velocity_54 | \n",
      "bar: 1  ==0               | 0               | 0               | Note            | Note_Pitch_69   | Note_Duration_1080 | Note_Velocity_95 | \n",
      "bar: 1  ==0               | 0               | 0               | Note            | Note_Pitch_45   | 0               | Note_Velocity_70 | \n",
      "bar: 1  ==0               | 0               | 0               | Note            | Note_Pitch_59   | Note_Duration_360 | Note_Velocity_88 | \n",
      "bar: 1  ==CONTI           | A_M7            | Beat_6          | Metrical        | 0               | 0               | Note_Velocity_13 | \n",
      "bar: 1  ==CONTI           | 0               | 0               | Note            | Note_Pitch_83   | Note_Duration_0 | Note_Velocity_5 | \n",
      "bar: 1  ==0               | 0               | 0               | Note            | Note_Pitch_52   | Note_Duration_1200 | Note_Velocity_30 | \n",
      "bar: 1  ==0               | CONTI           | Beat_9          | Metrical        | 0               | 0               | 0               | \n",
      "bar: 1  ==0               | C#_o7           | Beat_13         | EOS             | 0               | Note_Duration_240 | Note_Velocity_72 | \n",
      "\n",
      "--------[Done]--------\n",
      "(11, 7)\n",
      "------ generate ------\n",
      "bar: 1  ==Tempo_40        | B_m             | Beat_0          | Metrical        | 0               | 0               | Note_Velocity_74 | \n",
      "bar: 1  ==Tempo_60        | 0               | 0               | Note            | Note_Pitch_67   | Note_Duration_960 | Note_Velocity_81 | \n",
      "bar: 1  ==0               | A_+             | 0               | Note            | Note_Pitch_69   | Note_Duration_120 | Note_Velocity_51 | \n",
      "bar: 1  ==0               | 0               | 0               | Note            | Note_Pitch_64   | Note_Duration_360 | Note_Velocity_127 | \n",
      "bar: 1  ==0               | 0               | 0               | Note            | Note_Pitch_59   | Note_Duration_360 | Note_Velocity_31 | \n",
      "bar: 1  ==CONTI           | CONTI           | Beat_11         | Metrical        | 0               | 0               | Note_Velocity_127 | \n",
      "bar: 1  ==0               | 0               | 0               | Note            | Note_Pitch_88   | Note_Duration_960 | Note_Velocity_47 | \n",
      "bar: 1  ==0               | 0               | 0               | Note            | Note_Pitch_60   | Note_Duration_1080 | Note_Velocity_68 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bar: 1  ==0               | CONTI           | Bar             | Metrical        | 0               | Note_Duration_480 | Note_Velocity_40 | \n",
      "bar: 2  ==Tempo_210       | 0               | Beat_0          | EOS             | 0               | 0               | Note_Velocity_66 | \n",
      "\n",
      "--------[Done]--------\n",
      "(10, 7)\n"
     ]
    }
   ],
   "source": [
    "batch_size=1\n",
    "num_batch = len(test_x) // batch_size\n",
    "output_total=[]\n",
    "for bidx in range(5):\n",
    "    bidx_st = batch_size * bidx\n",
    "    bidx_ed = batch_size * (bidx + 1)\n",
    "  # unpack batch data\n",
    "    batch_x = test_x[bidx_st:bidx_ed]\n",
    "    batch_y = test_x[bidx_st:bidx_ed]\n",
    "    batch_mask = test_x[bidx_st:bidx_ed]\n",
    "    batch_x = torch.from_numpy(batch_x).long().to(device)\n",
    "    batch_y = torch.from_numpy(batch_y).long().to(device)\n",
    "    batch_mask = torch.from_numpy(batch_mask).float().to(device)\n",
    "    if isinstance(net, torch.nn.DataParallel):\n",
    "          net = net.module\n",
    "\n",
    "    src_mask=[]\n",
    "    for i in range(len(batch_x)):\n",
    "        src_mask.append(int(torch.where(batch_x[i][:,3]==0)[0][0]))\n",
    "    output=net.inference(batch_x,src_mask,dictionary)\n",
    "    output_total.append(output)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./result/0.mid\n",
      "./result/1.mid\n",
      "./result/2.mid\n",
      "./result/3.mid\n",
      "./result/4.mid\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(output_total)):\n",
    "    write_midi(output_total[i],'./result/'+str(i)+'.mid',word2event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
